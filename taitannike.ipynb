{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas #ipython notebook\n",
    "titanic = pandas.read_csv(\"titanic_train.csv\")\n",
    "titanic.head(3)\n",
    "#print(titanic.shape)\n",
    "#print (titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
      "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())#缺失值以age的平均值填充\n",
    "print(titanic.describe())\n",
    "titanic[\"Age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "#使用unique去掉重复值\n",
    "print(titanic[\"Sex\"].unique())\n",
    "# Replace all the occurences of male with the number 0.\n",
    "#以编码01取代性别字符\n",
    "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      2\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      1\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     2\n",
       "17     0\n",
       "18     0\n",
       "19     1\n",
       "20     0\n",
       "21     0\n",
       "22     2\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     1\n",
       "27     0\n",
       "28     2\n",
       "29     0\n",
       "      ..\n",
       "861    0\n",
       "862    0\n",
       "863    0\n",
       "864    0\n",
       "865    0\n",
       "866    1\n",
       "867    0\n",
       "868    0\n",
       "869    0\n",
       "870    0\n",
       "871    0\n",
       "872    0\n",
       "873    0\n",
       "874    1\n",
       "875    1\n",
       "876    0\n",
       "877    0\n",
       "878    0\n",
       "879    1\n",
       "880    0\n",
       "881    0\n",
       "882    0\n",
       "883    0\n",
       "884    0\n",
       "885    2\n",
       "886    0\n",
       "887    0\n",
       "888    0\n",
       "889    1\n",
       "890    2\n",
       "Name: Embarked, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(titanic[\"Embarked\"].unique())\n",
    "titanic[\"Embarked\"]\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('S')\n",
    "titanic.loc[titanic[\"Embarked\"] == \"S\",\"Embarked\"] = 0\n",
    "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "titanic.loc[:,\"Embarked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.KFold(n=891, n_folds=3, shuffle=False, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "# Import the linear regression class\n",
    "#线性回归模型\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Sklearn also has a helper that makes it easy to do cross validation\n",
    "#交叉验证模型\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm class\n",
    "alg = LinearRegression()\n",
    "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "print(kf)\n",
    "#titanic.shape[0]返回titanic行数，即样本数量m，对m个样本对交叉验证，n_folds做3层交叉验证，random_state=1随机种子数值为1\n",
    "predictions = []\n",
    "#print(train)\n",
    "#print(test)\n",
    "#print(kf)\n",
    "for train, test in kf:\n",
    "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "    train_predictors = (titanic[predictors].iloc[train,:])\n",
    "    #titanic[predictors].iloc[train,:]\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    #把训练集和目标集放到线性回归模型里训练\n",
    "    # We can now make predictions on the test fold\n",
    "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
    "    #把测试集放到训练好的线性回归模型里进行测试\n",
    "    predictions.append(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
    "# We concatenate them on axis 0, as they only have one axis.\n",
    "#print(predictions)\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "#print（accuracy）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  Sex   Age  SibSp  Parch      Fare  Embarked\n",
      "0         3    0  22.0      1      0    7.2500         0\n",
      "1         1    1  38.0      1      0   71.2833         1\n",
      "2         3    1  26.0      0      0    7.9250         0\n",
      "3         1    1  35.0      1      0   53.1000         0\n",
      "4         3    0  35.0      0      0    8.0500         0\n",
      "5         3    0  28.0      0      0    8.4583         2\n",
      "6         1    0  54.0      0      0   51.8625         0\n",
      "7         3    0   2.0      3      1   21.0750         0\n",
      "8         3    1  27.0      0      2   11.1333         0\n",
      "9         2    1  14.0      1      0   30.0708         1\n",
      "10        3    1   4.0      1      1   16.7000         0\n",
      "11        1    1  58.0      0      0   26.5500         0\n",
      "12        3    0  20.0      0      0    8.0500         0\n",
      "13        3    0  39.0      1      5   31.2750         0\n",
      "14        3    1  14.0      0      0    7.8542         0\n",
      "15        2    1  55.0      0      0   16.0000         0\n",
      "16        3    0   2.0      4      1   29.1250         2\n",
      "17        2    0  28.0      0      0   13.0000         0\n",
      "18        3    1  31.0      1      0   18.0000         0\n",
      "19        3    1  28.0      0      0    7.2250         1\n",
      "20        2    0  35.0      0      0   26.0000         0\n",
      "21        2    0  34.0      0      0   13.0000         0\n",
      "22        3    1  15.0      0      0    8.0292         2\n",
      "23        1    0  28.0      0      0   35.5000         0\n",
      "24        3    1   8.0      3      1   21.0750         0\n",
      "25        3    1  38.0      1      5   31.3875         0\n",
      "26        3    0  28.0      0      0    7.2250         1\n",
      "27        1    0  19.0      3      2  263.0000         0\n",
      "28        3    1  28.0      0      0    7.8792         2\n",
      "29        3    0  28.0      0      0    7.8958         0\n",
      "..      ...  ...   ...    ...    ...       ...       ...\n",
      "861       2    0  21.0      1      0   11.5000         0\n",
      "862       1    1  48.0      0      0   25.9292         0\n",
      "863       3    1  28.0      8      2   69.5500         0\n",
      "864       2    0  24.0      0      0   13.0000         0\n",
      "865       2    1  42.0      0      0   13.0000         0\n",
      "866       2    1  27.0      1      0   13.8583         1\n",
      "867       1    0  31.0      0      0   50.4958         0\n",
      "868       3    0  28.0      0      0    9.5000         0\n",
      "869       3    0   4.0      1      1   11.1333         0\n",
      "870       3    0  26.0      0      0    7.8958         0\n",
      "871       1    1  47.0      1      1   52.5542         0\n",
      "872       1    0  33.0      0      0    5.0000         0\n",
      "873       3    0  47.0      0      0    9.0000         0\n",
      "874       2    1  28.0      1      0   24.0000         1\n",
      "875       3    1  15.0      0      0    7.2250         1\n",
      "876       3    0  20.0      0      0    9.8458         0\n",
      "877       3    0  19.0      0      0    7.8958         0\n",
      "878       3    0  28.0      0      0    7.8958         0\n",
      "879       1    1  56.0      0      1   83.1583         1\n",
      "880       2    1  25.0      0      1   26.0000         0\n",
      "881       3    0  33.0      0      0    7.8958         0\n",
      "882       3    1  22.0      0      0   10.5167         0\n",
      "883       2    0  28.0      0      0   10.5000         0\n",
      "884       3    0  25.0      0      0    7.0500         0\n",
      "885       3    1  39.0      0      5   29.1250         2\n",
      "886       2    0  27.0      0      0   13.0000         0\n",
      "887       1    1  19.0      0      0   30.0000         0\n",
      "888       3    1  28.0      1      2   23.4500         0\n",
      "889       1    0  26.0      0      0   30.0000         1\n",
      "890       3    0  32.0      0      0    7.7500         2\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "0.787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize our algorithm\n",
    "#使用逻辑回归模型\n",
    "alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "#此使用说明见本人博客http://blog.sina.com.cn/s/blog_639a2ad70102xbix.html\n",
    "#使用交叉验证并求各交叉验证结果平均值\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(titanic[predictors])\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = pandas.read_csv(\"test.csv\")\n",
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0 \n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "#把属性字符串编码成数字便于模型处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785634118967\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm with the default paramters\n",
    "# n_estimators is the number of trees we want to make\n",
    "# min_samples_split is the minimum number of rows we need to make a split\n",
    "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "kf = cross_validation.KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.KFold(n=891, n_folds=3, shuffle=False, random_state=1)\n",
      "0.814814814815\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=100, min_samples_split=4, min_samples_leaf=2)\n",
    "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
    "#使用随机森林模型来预测样本。\n",
    "kf = cross_validation.KFold(titanic.shape[0], 3, random_state=1)\n",
    "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
    "print(kf)\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass                     Name  Sex   Age  SibSp  \\\n",
      "0            1         0       3  Braund, Mr. Owen Harris    0  22.0      1   \n",
      "\n",
      "   Parch     Ticket  Fare Cabin  Embarked  FamilySize  \n",
      "0      0  A/5 21171  7.25   NaN         0           1  \n",
      "   PassengerId  Survived  Pclass                     Name  Sex   Age  SibSp  \\\n",
      "0            1         0       3  Braund, Mr. Owen Harris    0  22.0      1   \n",
      "\n",
      "   Parch     Ticket  Fare Cabin  Embarked  FamilySize  NameLength  \n",
      "0      0  A/5 21171  7.25   NaN         0           1          23  \n"
     ]
    }
   ],
   "source": [
    "# Generating a familysize column\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "#增加家庭成员数量牲特征，内容是晚辈数量加长辈数量。\n",
    "print(titanic.head(1))\n",
    "# The .apply method generates a new series\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n",
    "#添加NameLength列，该列的内容如下：Name的内容经过（lambda x: len(x)）运算后形成的新一列。lambda相当于内建一个函数。即求Name的内容长度。\n",
    "print(titanic.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Mr\n",
      "1         Mrs\n",
      "2        Miss\n",
      "3         Mrs\n",
      "4          Mr\n",
      "5          Mr\n",
      "6          Mr\n",
      "7      Master\n",
      "8         Mrs\n",
      "9         Mrs\n",
      "10       Miss\n",
      "11       Miss\n",
      "12         Mr\n",
      "13         Mr\n",
      "14       Miss\n",
      "15        Mrs\n",
      "16     Master\n",
      "17         Mr\n",
      "18        Mrs\n",
      "19        Mrs\n",
      "20         Mr\n",
      "21         Mr\n",
      "22       Miss\n",
      "23         Mr\n",
      "24       Miss\n",
      "25        Mrs\n",
      "26         Mr\n",
      "27         Mr\n",
      "28       Miss\n",
      "29         Mr\n",
      "        ...  \n",
      "861        Mr\n",
      "862       Mrs\n",
      "863      Miss\n",
      "864        Mr\n",
      "865       Mrs\n",
      "866      Miss\n",
      "867        Mr\n",
      "868        Mr\n",
      "869    Master\n",
      "870        Mr\n",
      "871       Mrs\n",
      "872        Mr\n",
      "873        Mr\n",
      "874       Mrs\n",
      "875      Miss\n",
      "876        Mr\n",
      "877        Mr\n",
      "878        Mr\n",
      "879       Mrs\n",
      "880       Mrs\n",
      "881        Mr\n",
      "882      Miss\n",
      "883        Mr\n",
      "884        Mr\n",
      "885       Mrs\n",
      "886       Rev\n",
      "887      Miss\n",
      "888      Miss\n",
      "889        Mr\n",
      "890        Mr\n",
      "Name: Name, Length: 891, dtype: object\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#正则表达式模块\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "#正则表达式表示查找符合格式的字符串，格式为空格+英文字母+小数点,[A-Za-z]表示匹配A到Z和a-z的单个字母，加号表示多次匹配\n",
    "#即多个A到Z和a-z之间的字母\n",
    "# Get all the titles and print how often each one occurs.\n",
    "\n",
    "titles = titanic[\"Name\"].apply(get_title)\n",
    "#对Name列应用get_title运算规则，提取每个姓名的title\n",
    "print(titles)#每一个姓名的title各叫什么\n",
    "#print(pandas.value_counts(titles))\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "#k相当于\"Mr\"，v相当于1，如此类推。\n",
    "# Verify that we converted everything.\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Add in the title column.\n",
    "titanic[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3331fef2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"NameLength\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Pick only the four best features.\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=8, min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.279461279461\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\",]],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = titanic[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     240\n",
      "2      79\n",
      "3      72\n",
      "4      21\n",
      "7       2\n",
      "6       2\n",
      "10      1\n",
      "5       1\n",
      "Name: Title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "# We're adding the Dona title to the mapping, because it's in the test set, but not the training set\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "titanic_test[\"Title\"] = titles\n",
    "# Check the counts of each unique title.\n",
    "print(pandas.value_counts(titanic_test[\"Title\"]))\n",
    "\n",
    "# Now, we add the family size column.\n",
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11682912,  0.47835566,  0.12614824,  0.13098157,  0.52105874,\n",
       "        0.1435209 ,  0.64085331,  0.18003152,  0.67801353,  0.12111118,\n",
       "        0.12105181,  0.20902118,  0.91068381,  0.1089127 ,  0.89142102,\n",
       "        0.87713474,  0.16349859,  0.13907791,  0.54103238,  0.55661006,\n",
       "        0.22420875,  0.5372079 ,  0.90572223,  0.38890588,  0.88384752,\n",
       "        0.10357315,  0.90909441,  0.13746454,  0.31046249,  0.12665718,\n",
       "        0.11663767,  0.18274855,  0.55220994,  0.49648575,  0.42415297,\n",
       "        0.14191051,  0.50973638,  0.52452209,  0.13270506,  0.28366691,\n",
       "        0.11145281,  0.46618807,  0.09996501,  0.83420617,  0.89959119,\n",
       "        0.14983417,  0.31593419,  0.13789623,  0.89104185,  0.54189565,\n",
       "        0.35666363,  0.17718135,  0.8307195 ,  0.87995521,  0.1755907 ,\n",
       "        0.13741805,  0.10667279,  0.1234385 ,  0.12099736,  0.91285169,\n",
       "        0.13099159,  0.15341948,  0.12993967,  0.66573206,  0.66343836,\n",
       "        0.87272604,  0.67238712,  0.288265  ,  0.35236574,  0.85565507,\n",
       "        0.6622414 ,  0.12701993,  0.55390065,  0.36740462,  0.91110312,\n",
       "        0.41201902,  0.13014004,  0.83671279,  0.15614414,  0.6622414 ,\n",
       "        0.68129213,  0.20605719,  0.20382623,  0.12105181,  0.18486634,\n",
       "        0.13130212,  0.65680539,  0.53029858,  0.65489631,  0.79881212,\n",
       "        0.53764546,  0.12104028,  0.8913725 ,  0.13014004,  0.28406245,\n",
       "        0.12345367,  0.86792484,  0.14666337,  0.58599461,  0.12260781,\n",
       "        0.90433464,  0.14730817,  0.13789623,  0.12262433,  0.62257491,\n",
       "        0.13155874,  0.14607753,  0.13789623,  0.13020336,  0.17473033,\n",
       "        0.14286392,  0.65490316,  0.89528117,  0.67146758,  0.88346017,\n",
       "        0.13992078,  0.11805064,  0.69612515,  0.36668939,  0.86241698,\n",
       "        0.87649291,  0.12609327,  0.90276371,  0.12099027,  0.13789623,\n",
       "        0.56971935,  0.12608181,  0.63733743,  0.13339996,  0.13340574,\n",
       "        0.12723637,  0.51609607,  0.23921874,  0.10791695,  0.09896737,\n",
       "        0.12431124,  0.13346495,  0.16214099,  0.52029433,  0.12232635,\n",
       "        0.20712059,  0.90529649,  0.19747926,  0.16153716,  0.42927593,\n",
       "        0.10487176,  0.33642492,  0.13518414,  0.46618807,  0.34478758,\n",
       "        0.91431377,  0.13214999,  0.10690998,  0.48983645,  0.11274825,\n",
       "        0.12427868,  0.9107016 ,  0.57991631,  0.42927593,  0.51274048,\n",
       "        0.65489239,  0.57884522,  0.82113381,  0.12096648,  0.28979611,\n",
       "        0.58587108,  0.30130471,  0.14606803,  0.9025041 ,  0.52257377,\n",
       "        0.12101884,  0.13299498,  0.12418534,  0.13207486,  0.1319655 ,\n",
       "        0.8729358 ,  0.87633414,  0.29670328,  0.83389526,  0.85558679,\n",
       "        0.15614414,  0.33352246,  0.90219082,  0.13789623,  0.91718918,\n",
       "        0.13603003,  0.85482389,  0.12241402,  0.14217314,  0.13560687,\n",
       "        0.1348803 ,  0.25547183,  0.49950989,  0.12729496,  0.71980831,\n",
       "        0.10795469,  0.85516508,  0.58990449,  0.16645668,  0.53980354,\n",
       "        0.64867969,  0.66329187,  0.60981573,  0.87333314,  0.16322638,\n",
       "        0.25696649,  0.63083524,  0.16482591,  0.88984707,  0.12346408,\n",
       "        0.12849653,  0.12097124,  0.24675029,  0.80199995,  0.41248342,\n",
       "        0.29768148,  0.65492663,  0.21860346,  0.90027407,  0.13014004,\n",
       "        0.8137002 ,  0.13611142,  0.84275393,  0.12700828,  0.87789288,\n",
       "        0.59807994,  0.12518087,  0.65489631,  0.11487493,  0.1441311 ,\n",
       "        0.25075165,  0.89266286,  0.11622683,  0.1379133 ,  0.34224639,\n",
       "        0.12796773,  0.19365861,  0.14018901,  0.80948189,  0.89790832,\n",
       "        0.87598967,  0.82598174,  0.33036559,  0.12105101,  0.33258156,\n",
       "        0.28710745,  0.8790295 ,  0.16058987,  0.86241698,  0.59133092,\n",
       "        0.74586492,  0.15434326,  0.39647431,  0.13354268,  0.12701864,\n",
       "        0.12101884,  0.13789623,  0.13014004,  0.83005787,  0.12700585,\n",
       "        0.10894954,  0.12701508,  0.85003763,  0.64929875,  0.16619539,\n",
       "        0.12105181,  0.21821016,  0.12101884,  0.50973638,  0.14016481,\n",
       "        0.34495861,  0.13789623,  0.91564   ,  0.6332826 ,  0.13207439,\n",
       "        0.85713531,  0.15861636,  0.12500116,  0.14267175,  0.16811853,\n",
       "        0.52045075,  0.66231856,  0.65489631,  0.64136782,  0.71198852,\n",
       "        0.10601085,  0.12099027,  0.3627808 ,  0.13207486,  0.13014004,\n",
       "        0.33304456,  0.59319589,  0.13207486,  0.50584352,  0.12081676,\n",
       "        0.12263655,  0.77903176,  0.12665718,  0.33024483,  0.12028976,\n",
       "        0.11813957,  0.17547887,  0.1216941 ,  0.13347145,  0.65489631,\n",
       "        0.82133626,  0.33497525,  0.67696014,  0.20916505,  0.42575111,\n",
       "        0.13912869,  0.13799529,  0.12102122,  0.61904744,  0.90111957,\n",
       "        0.67393647,  0.23919457,  0.17328806,  0.12182854,  0.18522951,\n",
       "        0.12262433,  0.13491478,  0.16214099,  0.45541306,  0.90601333,\n",
       "        0.12509883,  0.86563776,  0.34598576,  0.14469719,  0.17034218,\n",
       "        0.82147627,  0.32823572,  0.13207439,  0.64322911,  0.12183262,\n",
       "        0.25111398,  0.15333425,  0.09370087,  0.20950803,  0.35411806,\n",
       "        0.17507148,  0.118123  ,  0.1469565 ,  0.91556464,  0.33657652,\n",
       "        0.618368  ,  0.16214099,  0.62462682,  0.1654289 ,  0.85157883,\n",
       "        0.89603825,  0.16322638,  0.24472808,  0.16066609,  0.70031025,\n",
       "        0.15642457,  0.85672648,  0.12105022,  0.13789623,  0.57255235,\n",
       "        0.10418822,  0.87672475,  0.86918839,  0.13098157,  0.91914163,\n",
       "        0.15715004,  0.1313025 ,  0.53322127,  0.89562968,  0.17356053,\n",
       "        0.15319843,  0.90891499,  0.16307942,  0.13130575,  0.87654859,\n",
       "        0.90969185,  0.48853359,  0.17002326,  0.19866966,  0.13510974,\n",
       "        0.13789623,  0.14010265,  0.54133852,  0.5949924 ,  0.15905635,\n",
       "        0.83276875,  0.12430276,  0.12019388,  0.14606637,  0.18789784,\n",
       "        0.38579307,  0.87750065,  0.56459193,  0.12807839,  0.10318132,\n",
       "        0.91169572,  0.14231524,  0.88773179,  0.12607946,  0.12971145,\n",
       "        0.90753797,  0.12635163,  0.90891637,  0.35988713,  0.30442425,\n",
       "        0.18966803,  0.1501521 ,  0.26822399,  0.65488945,  0.64585313,\n",
       "        0.65489631,  0.90711865,  0.56933478,  0.13014004,  0.86010063,\n",
       "        0.10126674,  0.13014004,  0.41850311])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"]\n",
    "\n",
    "algorithms = [\n",
    "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
    "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
    "]\n",
    "\n",
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
